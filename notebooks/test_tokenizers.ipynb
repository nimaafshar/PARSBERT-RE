{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load And Test different tokenizers for relation extraction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from persian_re.tokenizers import BertEntityMarkerTokenizer,BertPEEMTokenizer\n",
    "from persian_re.settings import MODEL_NAME_OR_PATH, MAX_LEN\n",
    "from persian_re.preprocess import PerlexData\n",
    "from persian_re.utils import pprint_relation_statement"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data = PerlexData.get_instance()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sample data\n",
    "**enitities and relation type**:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "جمله: کمیته پولیتزر یک <e1>\u001B[92mنقل‌قول \u001B[0m</e1>رسمی منتشر کرد که <e2>\u001B[91mدلایل \u001B[0m</e2>این جایزه را توضیح می دهد .\n",
      "Message-Topic(e1,e2)\n"
     ]
    }
   ],
   "source": [
    "sample_rs = data.x_train[12]\n",
    "sample_label = data.id2labels[data.y_train[12]]\n",
    "pprint_relation_statement(sample_rs)\n",
    "print(sample_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entity Marker Tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'BertEntityMarkerTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "em_tokenizer: BertEntityMarkerTokenizer = BertEntityMarkerTokenizer.from_pretrained(MODEL_NAME_OR_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "PreTrainedTokenizer(name_or_path='HooshvareLab/bert-fa-zwnj-base', vocab_size=42000, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['<e1>', '</e1>', '<e2>', '</e2>']})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**token ids:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\t\t\ttoken\n",
      "5049\t\tکمیته\n",
      "28982\t\tپولیتزر\n",
      "1961\t\tیک\n",
      "42000\t\t<e1>\n",
      "3470\t\tنقل\n",
      "9323\t\t##قول\n",
      "42001\t\t</e1>\n",
      "3291\t\tرسمی\n",
      "2596\t\tمنتشر\n",
      "1960\t\tکرد\n",
      "1932\t\tکه\n",
      "42002\t\t<e2>\n",
      "4701\t\tدلایل\n",
      "42003\t\t</e2>\n",
      "1930\t\tاین\n",
      "3817\t\tجایزه\n",
      "1937\t\tرا\n",
      "3730\t\tتوضیح\n",
      "1924\t\tمی\n",
      "2194\t\tدهد\n",
      "121\t\t.\n"
     ]
    }
   ],
   "source": [
    "tokens = em_tokenizer.tokenize(sample_rs)\n",
    "token_ids = em_tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(\"id\\t\\t\\ttoken\")\n",
    "for token, token_id in zip(tokens, token_ids):\n",
    "    print(f'{token_id}\\t\\t{token}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**encoding**: including *token_ids*, *segment_ids* and *attention_mask*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "encoding = em_tokenizer.encode_plus(\n",
    "    sample_rs,\n",
    "    max_length=MAX_LEN,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "    return_token_type_ids=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='max_length',\n",
    "    return_tensors='pt',  # Return PyTorch tensors\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[    2,  5049, 28982,  1961, 42000,  3470,  9323, 42001,  3291,  2596,\n          1960,  1932, 42002,  4701, 42003,  1930,  3817,  1937,  3730,  1924,\n          2194,   121,     3,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "ids = encoding['input_ids'][0].tolist()\n",
    "tokens = em_tokenizer.convert_ids_to_tokens(ids)\n",
    "segment_ids = encoding['token_type_ids'][0].tolist()\n",
    "attention_mask = encoding['attention_mask'][0].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "      token     id  segment_id  attention\n0     [CLS]      2           0          1\n1     کمیته   5049           0          1\n2   پولیتزر  28982           0          1\n3        یک   1961           0          1\n4      <e1>  42000           0          1\n..      ...    ...         ...        ...\n59    [PAD]      0           0          0\n60    [PAD]      0           0          0\n61    [PAD]      0           0          0\n62    [PAD]      0           0          0\n63    [PAD]      0           0          0\n\n[64 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>id</th>\n      <th>segment_id</th>\n      <th>attention</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS]</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>کمیته</td>\n      <td>5049</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>پولیتزر</td>\n      <td>28982</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>یک</td>\n      <td>1961</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;e1&gt;</td>\n      <td>42000</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>[PAD]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>[PAD]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>[PAD]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>[PAD]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>[PAD]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>64 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'token': tokens, 'id': ids, 'segment_id': segment_ids, 'attention': attention_mask})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entity Marker + Positional Embedding Tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'BertPEEMTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "peem_tokenizer: BertPEEMTokenizer = BertPEEMTokenizer.from_pretrained(MODEL_NAME_OR_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize Output\n",
    "**token ids:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\t\t\ttoken\n",
      "5049\t\tکمیته\n",
      "28982\t\tپولیتزر\n",
      "1961\t\tیک\n",
      "42000\t\t<e1>\n",
      "3470\t\tنقل\n",
      "9323\t\t##قول\n",
      "42001\t\t</e1>\n",
      "3291\t\tرسمی\n",
      "2596\t\tمنتشر\n",
      "1960\t\tکرد\n",
      "1932\t\tکه\n",
      "42002\t\t<e2>\n",
      "4701\t\tدلایل\n",
      "42003\t\t</e2>\n",
      "1930\t\tاین\n",
      "3817\t\tجایزه\n",
      "1937\t\tرا\n",
      "3730\t\tتوضیح\n",
      "1924\t\tمی\n",
      "2194\t\tدهد\n",
      "121\t\t.\n"
     ]
    }
   ],
   "source": [
    "tokens = peem_tokenizer.tokenize(sample_rs)\n",
    "token_ids = peem_tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(\"id\\t\\t\\ttoken\")\n",
    "for token, token_id in zip(tokens, token_ids):\n",
    "    print(f'{token_id}\\t\\t{token}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**encoding**: including *token_ids*, *segment_ids* and *attention_mask*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "encoding = peem_tokenizer.encode_plus(\n",
    "    sample_rs,\n",
    "    max_length=MAX_LEN,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "    return_token_type_ids=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='max_length',\n",
    "    return_tensors='pt',  # Return PyTorch tensors\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[    2,  5049, 28982,  1961, 42000,  3470,  9323, 42001,  3291,  2596,\n          1960,  1932, 42002,  4701, 42003,  1930,  3817,  1937,  3730,  1924,\n          2194,   121,     3,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "ids = encoding['input_ids'][0].tolist()\n",
    "tokens = peem_tokenizer.convert_ids_to_tokens(ids)\n",
    "segment_ids = encoding['token_type_ids'][0].tolist()\n",
    "attention_mask = encoding['attention_mask'][0].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "      token     id  segment_id  attention\n0     [CLS]      2           0          1\n1     کمیته   5049           0          1\n2   پولیتزر  28982           0          1\n3        یک   1961           0          1\n4      <e1>  42000           2          1\n..      ...    ...         ...        ...\n59    [PAD]      0           0          0\n60    [PAD]      0           0          0\n61    [PAD]      0           0          0\n62    [PAD]      0           0          0\n63    [PAD]      0           0          0\n\n[64 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>id</th>\n      <th>segment_id</th>\n      <th>attention</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS]</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>کمیته</td>\n      <td>5049</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>پولیتزر</td>\n      <td>28982</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>یک</td>\n      <td>1961</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;e1&gt;</td>\n      <td>42000</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>[PAD]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>[PAD]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>[PAD]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>[PAD]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>[PAD]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>64 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'token': tokens, 'id': ids, 'segment_id': segment_ids, 'attention': attention_mask})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}